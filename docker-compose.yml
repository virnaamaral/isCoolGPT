version: "3.9"

services:
  api:
    container_name: iscoolgpt-api
    build: .
    ports:
      - "8000:8000"
    environment:
      # Como o Ollama roda no HOST (Windows),
      # o container acessa ele por host.docker.internal
      OLLAMA_BASE_URL: "http://host.docker.internal:11434"
      OLLAMA_MODEL: "gemma3:1b"
    restart: unless-stopped
